{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation script for Imagenet models\n",
    "\n",
    "## Overview\n",
    "Use this notebook to verify the accuracy of a trained model on a validation set. It support all models {really? how about we list what is supported below?} trained on Imagenet {CamelCase!} dataset ([ILSVRC2012](http://www.image-net.org/challenges/LSVRC/2012/) and onwards).\n",
    "\n",
    "## Model Support in This Demo\n",
    "\n",
    "{list with links}\n",
    "\n",
    "## Prerequisites\n",
    "{list them (add min versions)}\n",
    "Also, you should have already trained imagenet and have the data somewhere...\n",
    "\n",
    "What is gluoncv!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guidelines for usage\n",
    "* The .onnx file for the model must be in the root folder {in / ? - that seems weird}\n",
    "* Install dependencies using cell below\n",
    "* Imagenet dataset must be downloaded and extracted in the required directory structure. Refer to the guidelines in the dataset section of [squeezenet readme](squeezenet/README.md).\n",
    "{the above sends you to an new page, which then doesn't say much and sends you to imagenet_prep.md. Add clarity and make use of the #anchors to go to the appropriate page sections directly.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install mxnet-cu90mkl #tested on this version, can use other versions\n",
    "!pip install gluoncv\n",
    "!pip install numpy\n",
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "from mxnet import gluon, nd\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from gluoncv.data import imagenet\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose context as cpu or gpu(recommended)\n",
    "# ctx = [mx.cpu()]\n",
    "ctx = [mx.gpu(0)]\n",
    "\n",
    "# path to imagenet dataset folder\n",
    "data_dir = '../imagenet/img_dataset'\n",
    "\n",
    "# batch size (set to 1 for cpu)\n",
    "batch_size = 128\n",
    "\n",
    "# number of preprocessing workers\n",
    "num_workers = 32\n",
    "\n",
    "# model name\n",
    "model_name = 'vgg16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import from ONNX format to MXNet symbols and params\n",
    "sym, arg_params, aux_params = import_model(model_name+'.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incase ONNX file not available - load MXNet symbols and params directly, skip otherwise\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint(model_name, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add clarity on each step... what is it doing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "mod = mx.mod.Module(symbol=sym, context=ctx, label_names=None)\n",
    "mod.bind(for_training=False, data_shapes=[('data', (1,3,224,224))], \n",
    "         label_shapes=mod._label_shapes)\n",
    "mod.set_params(arg_params, aux_params, allow_missing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since you're reusing a lot of the same code about resizing and normalizing, pull the values out, make them variables in a setup section and discuss them. Then you get to reuse that in each notebook.\n",
    "\n",
    "Explain what is happening in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define evaluation metrics\n",
    "acc_top1 = mx.metric.Accuracy()\n",
    "acc_top5 = mx.metric.TopKAccuracy(5)\n",
    "\n",
    "# Define image transforms\n",
    "normalize = transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])\n",
    "\n",
    "# Prepare input\n",
    "val_data = gluon.data.DataLoader(\n",
    "    imagenet.classification.ImageNet(data_dir, train=False).transform_first(transform_test),\n",
    "    batch_size=batch_size, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capital Batch?\n",
    "Explain what this section is doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Compute evaluations\n",
    "Batch = namedtuple('Batch', ['data'])\n",
    "acc_top1.reset()\n",
    "acc_top5.reset()\n",
    "num_batches = int(50000/batch_size)\n",
    "print('[0 / %d] batches done'%(num_batches))\n",
    "for i, batch in enumerate(val_data):\n",
    "    data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "    label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "    mod.forward(Batch([data[0]]))\n",
    "    outputs=mod.get_outputs()\n",
    "    acc_top1.update(label, outputs)\n",
    "    acc_top5.update(label, outputs)\n",
    "    if (i+1)%50==0:\n",
    "        print('[%d / %d] batches done'%(i+1,num_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "_, top1 = acc_top1.get()\n",
    "_, top5 = acc_top5.get()\n",
    "print('top1 error:',1-top1,'; top-5 error:',1-top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{This validation is backwards isn't? I'm used to seeing something accuracy, not error.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
